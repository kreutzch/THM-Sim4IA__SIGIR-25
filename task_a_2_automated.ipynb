{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed38a5a7",
   "metadata": {},
   "source": [
    "#### Task A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pyterrier as pt\n",
    "from llm_hlp import next_queries_gemini, next_queries_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenAI_token.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = content\n",
    "\n",
    "with open('Gemini_token.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    os.environ[\"GEMINI_API_KEY\"] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pt.java.started():\n",
    "    pt.java.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = os.path.abspath(\"./example_data/index_CORE\") # modify if needed\n",
    "index_ref = pt.IndexRef.of(index_path)\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "meta_ind = index.getMetaIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"You are tasked with writing potential next queries for a multiple given queries and already clicked on documents.\"\n",
    "# change this example prompt and put it in your strategy\n",
    "# you can also change the instruction IF YOU KNOW WHAT YOU ARE DOING\n",
    "# if not, please just let them be\n",
    "prompt_instructions = 'You are required to return EXACTLY %NUMOFQUERIES% potential next queries, NOTHING ELSE. Queries need to be distinct from each other. Order them in descending order by probability of them being the next query. Return these next %NUMOFQUERIES% queries as a Python-style list. These are the previous queries (preceded by \"?\") as well as the corresponding clicked on documents (preceded by \">\"):\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9130ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these variables\n",
    "\n",
    "use_gpt = False\n",
    "modelname = 'gemini-2.0-flash' # 'gpt-4.1-nano' # 'gemini-2.0-flash' #'gemini-2.5-flash-preview-05-20' # 'gemini-2.0-flash'\n",
    "\n",
    "name = 'this-is-my-name' \n",
    "strategy = 'This is my strategy ......' +\\\n",
    "    '_____ PROMPT: ' + example_prompt + ' _____ INSTRUCTION: ' + prompt_instructions + ' _____ LLM: ' + modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('task_A_2_automated_' + modelname + '--' + name + '.json'):\n",
    "    with open('task_A_2_automated_' + modelname + '--' + name + '.json', 'w') as f:\n",
    "        json.dump({'name': name, 'strategy': strategy}, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917c95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv('predetermined_queries_Task_A_test.csv', header = None)\n",
    "    \n",
    "with open('task_A_2_automated_' + modelname + '--' + name + '.json') as f:\n",
    "    next_queries = json.load(f)\n",
    "\n",
    "for qu_id in queries[2].unique():\n",
    "    squ_id = str(qu_id)\n",
    "    if squ_id not in next_queries or len(next_queries[squ_id]) < 10:\n",
    "        text_for_llm = ''\n",
    "        for i, row in queries[queries[2] == qu_id].iterrows():\n",
    "            text_for_llm += '?: ' + row[3] + '\\n'\n",
    "\n",
    "            for relevant_doc in row[5][1:-1].split(', '):\n",
    "                doc_no = meta_ind.getDocument('docno', str(relevant_doc))\n",
    "                if doc_no > -1:\n",
    "                    doc_cont = meta_ind.getItem(\"title\", doc_no)   \n",
    "                \n",
    "                    text_for_llm += '>: ' + doc_cont + '\\n'\n",
    "\n",
    "            text_for_llm += '--\\n'\n",
    "        \n",
    "        next_new_queries = []\n",
    "        already_entered_queries = []\n",
    "        already_entered_queries_for_llm = ''\n",
    "        if squ_id in next_queries:\n",
    "            next_new_queries = next_queries[squ_id]\n",
    "        \n",
    "            for i in range(len(next_new_queries)):\n",
    "                already_entered_queries.append(next_new_queries[i])\n",
    "                already_entered_queries_for_llm += next_new_queries[i] + ', '\n",
    "        \n",
    "        if len(already_entered_queries) > 0:\n",
    "            curr_prompt_instructions = ' These queries have already been written as potential next ones, YOU CANNOT REPEAT THEM: ' + already_entered_queries_for_llm[:-2] + '. ' + prompt_instructions\n",
    "        else:\n",
    "            curr_prompt_instructions = prompt_instructions\n",
    "            \n",
    "        print(example_prompt + ' ' + curr_prompt_instructions.replace('%NUMOFQUERIES%', str(10 - len(already_entered_queries))) + ' ' + text_for_llm)\n",
    "                \n",
    "        if use_gpt:\n",
    "            potential_next_queries, error_occurred = next_queries_gpt(text_for_llm, example_prompt, 10 - len(already_entered_queries), curr_prompt_instructions. modelname)\n",
    "        else:\n",
    "            potential_next_queries, error_occurred = next_queries_gemini(text_for_llm, example_prompt, 10 - len(already_entered_queries), curr_prompt_instructions, modelname)\n",
    "\n",
    "        for new_query in potential_next_queries:\n",
    "            if len(next_new_queries) < 11:\n",
    "                next_new_queries.append(new_query)\n",
    "        next_queries[str(squ_id)] = next_new_queries\n",
    "        \n",
    "        with open('task_A_2_automated_' + modelname +'--' + name + '.json', 'w') as f:\n",
    "            json.dump(next_queries, f, indent = 2)\n",
    "            \n",
    "        print('These ' + str(len(next_new_queries)) + ' options have been entered by the LLM as potential next queries:')\n",
    "        for i in range(len(next_new_queries)):\n",
    "            print(str(i + 1) + ' -- ' + next_new_queries[i])\n",
    "        \n",
    "        if len(potential_next_queries) + len(already_entered_queries) != 10:\n",
    "            print('Please run this query again, there have only been ' + str(len(next_new_queries)) + ' queries.')\n",
    "\n",
    "        print('Thanks!')\n",
    "        break\n",
    "    \n",
    "if len(next_queries) == 35:\n",
    "    print('Nice job, well done! Please send your `task_A_2_automated_' + modelname + '--' + name + '.json` file to Christin. Thank you so much! :)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
